{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91158cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\lucas\\\\Desktop\\\\Projects\\\\CLIP Card Retreival\\\\Datasets\\\\YoloFineTuning'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21f4cdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8x.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d45d631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.202  Python-3.12.11 torch-2.8.0+cpu CPU (11th Gen Intel Core i7-1165G7 @ 2.80GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8x.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\lucas\\Desktop\\Projects\\CLIP Card Retreival\\Datasets\\YoloFineTuning\\runs\\detect\\train2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8718931  ultralytics.nn.modules.head.Detect           [1, [320, 640, 640]]          \n",
      "Model summary: 209 layers, 68,153,571 parameters, 68,153,555 gradients, 258.1 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 201.7414.7 MB/s, size: 162.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\lucas\\Desktop\\Projects\\CLIP Card Retreival\\Datasets\\YoloFineTuning\\labels\\train... 750 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 750/750 297.1it/s 2.5s0.1s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\lucas\\Desktop\\Projects\\CLIP Card Retreival\\Datasets\\YoloFineTuning\\labels\\train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 14.04.0 MB/s, size: 160.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\lucas\\Desktop\\Projects\\CLIP Card Retreival\\Datasets\\YoloFineTuning\\labels\\val... 250 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 250/250 286.6it/s 0.9s0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\lucas\\Desktop\\Projects\\CLIP Card Retreival\\Datasets\\YoloFineTuning\\labels\\val.cache\n",
      "Plotting labels to C:\\Users\\lucas\\Desktop\\Projects\\CLIP Card Retreival\\Datasets\\YoloFineTuning\\runs\\detect\\train2\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\lucas\\Desktop\\Projects\\CLIP Card Retreival\\Datasets\\YoloFineTuning\\runs\\detect\\train2\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/10         0G     0.4888     0.8905     0.9746         14        256: 100% ━━━━━━━━━━━━ 47/47 0.1it/s 8:4710.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.1it/s 1:06<9.2ss\n",
      "                   all        250        250    0.00479      0.436    0.00374    0.00168\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/10         0G      0.692     0.7325      1.093         14        256: 100% ━━━━━━━━━━━━ 47/47 0.1it/s 8:3410.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.1it/s 1:05<9.1ss\n",
      "                   all        250        250    0.00482      0.408    0.00336    0.00112\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/10         0G     0.6622     0.6464      1.083         14        256: 100% ━━━━━━━━━━━━ 47/47 0.1it/s 8:3410.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.1it/s 1:06<9.2ss\n",
      "                   all        250        250      0.105      0.044     0.0516    0.00559\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/10         0G     0.5749     0.5359      1.012         14        256: 100% ━━━━━━━━━━━━ 47/47 0.1it/s 8:3310.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.1it/s 1:06<9.2ss\n",
      "                   all        250        250      0.621       0.66      0.678      0.495\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/10         0G     0.4909      0.461     0.9589         14        256: 100% ━━━━━━━━━━━━ 47/47 0.1it/s 8:3010.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.1it/s 1:06<9.2ss\n",
      "                   all        250        250      0.801      0.752       0.83      0.733\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/10         0G     0.4161     0.3811     0.9108         14        256: 100% ━━━━━━━━━━━━ 47/47 0.1it/s 8:3010.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.1it/s 1:07<9.3ss\n",
      "                   all        250        250      0.965      0.988      0.993      0.936\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/10         0G     0.4073     0.3704      0.911         14        256: 100% ━━━━━━━━━━━━ 47/47 0.1it/s 8:3710.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.1it/s 1:06<9.2ss\n",
      "                   all        250        250      0.976      0.989      0.993      0.954\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/10         0G     0.3206     0.3099     0.8782         14        256: 100% ━━━━━━━━━━━━ 47/47 0.1it/s 8:2410.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.1it/s 1:06<9.1ss\n",
      "                   all        250        250      0.994          1      0.995      0.971\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/10         0G     0.3024     0.2842     0.8669         14        256: 100% ━━━━━━━━━━━━ 47/47 0.1it/s 10:0015.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.1it/s 58.6s8.3ss\n",
      "                   all        250        250          1      0.992      0.995      0.986\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/10         0G     0.2586     0.2455      0.849         14        256: 100% ━━━━━━━━━━━━ 47/47 0.1it/s 13:1319.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.1it/s 1:5816.4s\n",
      "                   all        250        250          1          1      0.995       0.99\n",
      "\n",
      "10 epochs completed in 1.735 hours.\n",
      "Optimizer stripped from C:\\Users\\lucas\\Desktop\\Projects\\CLIP Card Retreival\\Datasets\\YoloFineTuning\\runs\\detect\\train2\\weights\\last.pt, 136.7MB\n",
      "Optimizer stripped from C:\\Users\\lucas\\Desktop\\Projects\\CLIP Card Retreival\\Datasets\\YoloFineTuning\\runs\\detect\\train2\\weights\\best.pt, 136.7MB\n",
      "\n",
      "Validating C:\\Users\\lucas\\Desktop\\Projects\\CLIP Card Retreival\\Datasets\\YoloFineTuning\\runs\\detect\\train2\\weights\\best.pt...\n",
      "Ultralytics 8.3.202  Python-3.12.11 torch-2.8.0+cpu CPU (11th Gen Intel Core i7-1165G7 @ 2.80GHz)\n",
      "Model summary (fused): 112 layers, 68,124,531 parameters, 0 gradients, 257.4 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 0.1it/s 1:5315.7s\n",
      "                   all        250        250          1          1      0.995       0.99\n",
      "Speed: 0.5ms preprocess, 439.6ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\lucas\\Desktop\\Projects\\CLIP Card Retreival\\Datasets\\YoloFineTuning\\runs\\detect\\train2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.train(\n",
    "    data = \"data.yaml\",\n",
    "    batch = 16,\n",
    "    epochs=10,\n",
    "    imgsz=256\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "564e5dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.202  Python-3.12.11 torch-2.8.0+cpu CPU (11th Gen Intel Core i7-1165G7 @ 2.80GHz)\n",
      "Model summary (fused): 112 layers, 68,124,531 parameters, 0 gradients, 257.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 350.255.9 MB/s, size: 156.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\lucas\\Desktop\\Projects\\CLIP Card Retreival\\Datasets\\YoloFineTuning\\labels\\val.cache... 250 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 250/250 120.4Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 16/16 0.1it/s 1:577.5ss\n",
      "                   all        250        250          1      0.812      0.906      0.894\n",
      "Speed: 0.5ms preprocess, 453.6ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\lucas\\Desktop\\Projects\\CLIP Card Retreival\\Datasets\\YoloFineTuning\\runs\\detect\\val2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
    "\n",
    "metrics = model.val(\n",
    "    data = \"data.yaml\",\n",
    "    split = \"val\",\n",
    "    imgsz = 256,\n",
    "    conf = 0.9\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Gastly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
